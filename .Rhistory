data(classscores)
data <- data.frame(Mechanics_C=ma[,1],
Vectors_C=ma[,2],
Algebra_O=ma[,3],
Analysis_O=ma[,4],
Statistics_O=ma[,5])
# I read the [84] An Introduction to the Bootstrap by Bradley Efron, Robert J. Tibshirani, p63, and I find he used the bias the estimator of cov with denominator n. However, in r package cov uses denominator n - 1 to ensure unbiased.
cp_cov <- function(data, bycol = TRUE){
if(bycol!=TRUE){data <- t(data)}
n <- dim(data)[2] # col
m <- dim(data)[1] # row
covc <- matrix(ncol = n,nrow = n)
for (i in 1:n) {
for (j in 1:n) {
covc[i,j] <- (m-1)/m*cov(data[,i],data[,j])
}
}
return(covc)
}
# We developed a function to calculate the eigenvalues.
theta_func <- function(data,demo_by_n = FALSE){
data_cov <- cov(data) # calculate the covariance matrix
if(demo_by_n == TRUE){data_cov <- cp_cov(data)}
ev       <- eigen(data_cov)$values # calculate the eigenvalues of cov matrix
theta    <- ev[1]/sum(ev) # return the eigenvalues sorted in decreasing order
return(c(theta,ev))
}
round(theta_func(data,1)[2:6],1) # denominated by n
# we first calculate the same values as reported.
theta_func(data,1)[1] # denominated by n
theta_func(data,0)[1] # denominated by n-1
# we find the estimator of theta is equal, haha
data(classscores)
data <- data.frame(Mechanics_C=ma[,1],
Vectors_C=ma[,2],
Algebra_O=ma[,3],
Analysis_O=ma[,4],
Statistics_O=ma[,5])
# I read the [84] An Introduction to the Bootstrap by Bradley Efron, Robert J. Tibshirani, p63, and I find he used the bias the estimator of cov with denominator n. However, in r package cov uses denominator n - 1 to ensure unbiased.
cp_cov <- function(data, bycol = TRUE){
if(bycol!=TRUE){data <- t(data)}
n <- dim(data)[2] # col
m <- dim(data)[1] # row
covc <- matrix(ncol = n,nrow = n)
for (i in 1:n) {
for (j in 1:n) {
covc[i,j] <- (m-1)/m*cov(data[,i],data[,j])
}
}
return(covc)
}
# We developed a function to calculate the eigenvalues.
theta_func <- function(data,demo_by_n = FALSE){
data_cov <- cov(data) # calculate the covariance matrix
if(demo_by_n == TRUE){data_cov <- cp_cov(data)}
ev       <- eigen(data_cov)$values # calculate the eigenvalues of cov matrix
theta    <- ev[1]/sum(ev) # return the eigenvalues sorted in decreasing order
return(c(theta,ev))
}
round(theta_func(data,1)[2:6],1) # denominated by n
# we first calculate the same values as reported.
theta_func(data,1)[1] # denominated by n
theta_func(data,0)[1] # denominated by n-1
# we find the estimator of theta is equal, haha
data(classscores)
load("../data/classscores.rdata")
devtools::check()
devtools::check()
devtools::document()
devtools::document()
devtools::check()
matrixStats::rowMeans
matrixStats::rowMeans2
?matrixStats::rowMeans2
# generate samples from N(0,1) to form matrix as sm
sm_ge <- function(p = 1, n = 10, e = 0){
sm <- matrix(nrow = p, ncol = n)
sigma <- sample(c(1, 10), replace = TRUE, size = n, prob = c(1-e, e))
for (pj in 1:p) {
sm[pj,] <- rnorm(n, 0, sigma)
}
return(sm)
}
mmm <- sm_ge()
mmm
rowMeans(mmm)
matrixStats::rowMeans2(mmm)
devtools::check()
devtools::check()
devtools::document()
devtools::check()
devtools::build_vignettes()
warnings()
devtools::check()
devtools::check()
devtools::check()
devtools::document()
devtools::check()
usethis::use_data(Gs)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
data(Q)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
save(Gs,file = "./data/Gs.rda")
save(Gs,file = "./data/Gs.rda",compress = TRUE)
load("~/Desktop/StatComp21047/data/Gs.rda")
load("~/Desktop/StatComp21047/data/Gs.rdata")
usethis::use_data(Gs)
usethis::use_data(Gs)
usethis::use_data(Gs)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
View(ma)
devtools::check()
devtools::check()
knitr::opts_chunk$set(echo = TRUE)
# generate f1 and f2 distribution using acceptance method
f1 <- function(x){
y <- dnorm(x)/pnorm(-1)
return(y)}
f2 <- function(x){
y <- sqrt(exp(1))*x*exp(-x**2/2)
return(y)}
# n samples from f1 and f2
fx <- function(n = 1e3){
x1 <- x2 <- numeric(n)
res <- matrix(ncol = n,nrow = 2)
i  <- j  <- 1
while (i <= n || j <= n) {
y  <- runif(1)
x <- runif(1,1,n)
if(f1(x) > y && i<= n ){
# we accept x
x1[i] <- x
i <- i + 1
}
if(f2(x) >y && j<= n){
x2[j] <- x
j = j + 1
}
}
res[1,] <- x1
res[2,] <- x2
return(res)
}
# calculate one g1 and g2 with n samples
g <- function(n = 1e3){
x <- fx(n)
y1  <- x[1,]^2*pnorm(-1)
me1 <- mean(y1)
sd1 <- mean(y1^2) - me1^2
y2  <- x[2,]/sqrt(2*pi*exp(1))
me2 <- mean(y2)
sd2 <- mean(y2^2) - me2^2
res = c(me1,sd1,me2,sd2)
return(res)
}
# calculate m gs with m groups
m <- 2 # change it to a larger one if you want to get concise data
ma <- matrix(ncol = 4,nrow = m)
for (j in seq(1:m)) {
ma[j,] <- g()
}
knitr::kable(
data.frame(
g1_thm = c(Eg, Varg1/m),
g1_act = c(mean(ma[,1]),mean(ma[,2])/m),
g2_thm = c(Eg, Varg2/m),
g2_act = c(mean(ma[,3]),mean(ma[,4])/m),
row.names = c("Mean","Var")
))
load("../data/classscores.rdata")
load("~/Desktop/StatComp21047/data/classscores.rdata")
classscores <- ma
usethis::use_data(classscores)
load("../data/classscores.rdata")
load("../data/classscores.rda")
load("./data/classscores.rda")
usethis::use_data(mafor5.14)
mafor5.14 <- matrix(ncol = 4,nrow = m)
for (j in seq(1:m)) {
mafor5.14[j,] <- g()
}
usethis::use_data(mafor5.14)
devtools::check()
devtools::check()
load("~/Desktop/StatComp21047/data/resfor7Bnorm.rdata")
load("~/Desktop/StatComp21047/data/resfor7Bnorm.rdata")
resfor7Bnorm <- check_bs_ci(func = "norm")
library(boot)
library(progress)
check_bs_ci <- function(sample_size=500, mc = 1e3, func="norm"){
bs_ci_norm <- bs_ci_basi <- bs_ci_perc <- matrix(NA, mc, 2)
pb <- progress_bar$new(total = mc)
msk <- switch (func,
norm  = 0,
chisq = 2*sqrt(2/5)
)
for (m in 1:mc){
x <- switch (func,
norm  = rnorm(sample_size),
chisq = rchisq(sample_size,df=4) # n = 5, df = 4
)
bs    <- boot(x,statistic = boot_skew, R=sample_size) # 1 sampling with sample_size
bs_ci <- boot.ci(bs,type = c("norm","basic", "perc"))
bs_ci_norm[m,] <- bs_ci$norm[2:3]
bs_ci_basi[m,] <- bs_ci$basic[4:5]
bs_ci_perc[m,] <- bs_ci$percent[4:5]
pb$tick() #if (m %% (mc/10) == 0){print(cat("loading =", (m/mc)*100,"%"))}
}
CI_norm <- c(mean(bs_ci_norm[,1]),mean(bs_ci_norm[,2]))
CI_norm_alpha_L <- mean(bs_ci_norm[,1] > msk)
CI_norm_alpha_R <- mean(bs_ci_norm[,2] < msk)
CI_norm_alpha   <- mean(bs_ci_norm[,1] <= msk & bs_ci_norm[,2] >= msk)
CI_basi <- c(mean(bs_ci_basi[,1]),mean(bs_ci_basi[,2]))
CI_basi_alpha_L <- mean(bs_ci_basi[,1] > msk)
CI_basi_alpha_R <- mean(bs_ci_basi[,2] < msk)
CI_basi_alpha   <- mean(bs_ci_basi[,1] <= msk & bs_ci_basi[,2] >= msk)
CI_perc <- c(mean(bs_ci_perc[,1]),mean(bs_ci_perc[,2]))
CI_perc_alpha_L <- mean(bs_ci_perc[,1] > msk)
CI_perc_alpha_R <- mean(bs_ci_perc[,2] < msk)
CI_perc_alpha   <- mean(bs_ci_perc[,1] <= msk & bs_ci_perc[,2] >= msk)
df <- data.frame(ID=c("Norm","Basi","Perc"),
Alpha_L = c(CI_norm_alpha_L,CI_basi_alpha_L,CI_perc_alpha_L),
Alpha_M = c(CI_norm_alpha  ,CI_basi_alpha  ,CI_perc_alpha  ),
Alpha_R = c(CI_norm_alpha_R,CI_basi_alpha_R,CI_perc_alpha_R),
CI_L    = c(CI_norm[1]     ,CI_basi[1]     ,CI_perc[1]     ),
CI_R    = c(CI_norm[2]     ,CI_basi[2]     ,CI_perc[2]     ))
print(df)
return(df)
}
#resfor7Bchisq <- check_bs_ci(func = "chisq")
load("../data/resfor7Bchisq.rdata")
resfor7Bnorm <- check_bs_ci(func = "norm")
# define sk and sk_boot to calculate the value out.
sk <- function(x,justi=FALSE){
n <- length(x)
if (justi == TRUE){
skew <- 1/n*sum((x-mean(x))^3)/(sd(x)*sqrt((n-1)/n))^3
} else {
skew <- 1/n*sum((x-mean(x))^3)/sd(x)^3
}
return(skew)
}
boot_skew <- function(x,i){
skew <- sk(x[i],TRUE)
return(skew)
}
library(boot)
library(progress)
check_bs_ci <- function(sample_size=500, mc = 1e3, func="norm"){
bs_ci_norm <- bs_ci_basi <- bs_ci_perc <- matrix(NA, mc, 2)
pb <- progress_bar$new(total = mc)
msk <- switch (func,
norm  = 0,
chisq = 2*sqrt(2/5)
)
for (m in 1:mc){
x <- switch (func,
norm  = rnorm(sample_size),
chisq = rchisq(sample_size,df=4) # n = 5, df = 4
)
bs    <- boot(x,statistic = boot_skew, R=sample_size) # 1 sampling with sample_size
bs_ci <- boot.ci(bs,type = c("norm","basic", "perc"))
bs_ci_norm[m,] <- bs_ci$norm[2:3]
bs_ci_basi[m,] <- bs_ci$basic[4:5]
bs_ci_perc[m,] <- bs_ci$percent[4:5]
pb$tick() #if (m %% (mc/10) == 0){print(cat("loading =", (m/mc)*100,"%"))}
}
CI_norm <- c(mean(bs_ci_norm[,1]),mean(bs_ci_norm[,2]))
CI_norm_alpha_L <- mean(bs_ci_norm[,1] > msk)
CI_norm_alpha_R <- mean(bs_ci_norm[,2] < msk)
CI_norm_alpha   <- mean(bs_ci_norm[,1] <= msk & bs_ci_norm[,2] >= msk)
CI_basi <- c(mean(bs_ci_basi[,1]),mean(bs_ci_basi[,2]))
CI_basi_alpha_L <- mean(bs_ci_basi[,1] > msk)
CI_basi_alpha_R <- mean(bs_ci_basi[,2] < msk)
CI_basi_alpha   <- mean(bs_ci_basi[,1] <= msk & bs_ci_basi[,2] >= msk)
CI_perc <- c(mean(bs_ci_perc[,1]),mean(bs_ci_perc[,2]))
CI_perc_alpha_L <- mean(bs_ci_perc[,1] > msk)
CI_perc_alpha_R <- mean(bs_ci_perc[,2] < msk)
CI_perc_alpha   <- mean(bs_ci_perc[,1] <= msk & bs_ci_perc[,2] >= msk)
df <- data.frame(ID=c("Norm","Basi","Perc"),
Alpha_L = c(CI_norm_alpha_L,CI_basi_alpha_L,CI_perc_alpha_L),
Alpha_M = c(CI_norm_alpha  ,CI_basi_alpha  ,CI_perc_alpha  ),
Alpha_R = c(CI_norm_alpha_R,CI_basi_alpha_R,CI_perc_alpha_R),
CI_L    = c(CI_norm[1]     ,CI_basi[1]     ,CI_perc[1]     ),
CI_R    = c(CI_norm[2]     ,CI_basi[2]     ,CI_perc[2]     ))
print(df)
return(df)
}
#resfor7Bchisq <- check_bs_ci(func = "chisq")
load("../data/resfor7Bchisq.rdata")
resfor7Bnorm <- check_bs_ci(func = "norm")
#load("../data/resfor7Bnorm.rdata")
usethis::use_data(resfor7Bnorm)
usethis::use_data(resfor7Bchisq)
devtools::check()
devtools::check()
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
install.packages('../StatComp_1.0.tar.gz',repo=NULL)
install.packages('../StatComp21047.tar.gz',repo=NULL)
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
library(StatComp21047)
?cp_gibbs
??cp_gibbs
?StatComp
??StatComp
??cp_gibbs
Q
library(StatComp21047)
cp_gibbsR()
?cp_gibbsR()
help("StatComp21047-package")
help("StatComp21047")
StatComp21047
devtools::check()
devtools::test()
devtools::test()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::build(vignettes=FALSE)
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
remove.packages("StatComp21047")
remove.packages("StatComp21047")
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
library(StatComp21047)
devtools::build(vignettes=FALSE)
remove.packages("StatComp21047")
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
library(StatComp21047)
?cp_gibbsC
?cp_gibbsC
devtools::document()
devtools::check()
devtools::check()
library(StatComp21047)
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
devtools::document()
devtools::check()
devtools::build(vignettes=FALSE)
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
library(StatComp21047)
library(StatComp21047)
library(StatComp21047)
data("Q")
help("cp_gibbsR")
?`StatComp21047-package`
?StatComp21047-package`
load("../data/Ts.rdata")
load("./data/Ts.rdata")
load("./data/Gs.rda")
knitr::opts_chunk$set(echo = TRUE)
CW_map       <- c(4,12) # the map size
CW_epsilon   <- 0.1 # the prob that random policy uses
CW_discount  <- 1.0 # the discount factor that reward uses
CW_actions   <- c(1,2,3,4) # direction: 1 UP, 2 Right, 3 Down, 4 Left
CW_start_pos <- c(4,1) # start position
CW_end_pos   <- c(4,12) # end position
CW_num_episodes <- 1e4 # episodes numbers
library(progress) # demonstrate the progress when training
CW_reset_Q <- function(){
# this function is performed to initialize the Q to feasible action prob
Q <- array(1.0,dim = c(CW_map[1],CW_map[2],4))
Q[,1,4] <- NA
Q[,CW_map[2],2] <- NA
Q[1,,1] <- NA
Q[CW_map[1],,3] <- NA
for (i in 1:CW_map[1]){
for (j in 1:CW_map[2]){
Q[i,j,] <- Q[i,j,] / sum(Q[i,j,],na.rm = TRUE)
}
}
return(Q)
}
CW_get_action_epsilon_policy <- function(Q,s_cur,epsilon=CW_epsilon){
# generate feasible actions based on Q and epsilon.
Qs <- Q[s_cur[1],s_cur[2],]
nna <- which(!is.na(Qs))
q_based <- Qs[nna]
a_based <- CW_actions[nna]
action <- sample(a_based,1)
if (runif(1) >= epsilon){
a_max  <- a_based[q_based == max(q_based,na.rm = TRUE)]
if (length(a_max) > 1){
action <- sample(a_max,1) # The modified one
}
if (length(a_max) == 1){
action <- a_max
}
}
return(action)
}
CW_take_a_step <- function(state,action){
# take one step at state and action, we cat reward and next_state
next_state <- switch (action,
# "1" = c(max(state[1]-1,1),state[2]),
# "2" = c(state[1],min(state[2]+1, CW_map[2])),
# "3" = c(min(state[1]+1,CW_map[1]),state[2]),
# "4" = c(state[1],max(state[2]-1,1))
"1" = c(state[1]-1,state[2]),
"2" = c(state[1],state[2]+1),
"3" = c(state[1]+1,state[2]),
"4" = c(state[1],state[2]-1),
)
reward <- -1
if(next_state[1] == 4 & next_state[2] <= 11 & next_state[2] >= 2){
reward <- -100
next_state <- CW_start_pos
}
return(list(next_state,reward))
}
CW_one_episode <- function(Q,epsilon=CW_epsilon){
# generate one episode based one Q
reward  <- 0
state   <- CW_start_pos
action  <- CW_get_action_epsilon_policy(Q,state,epsilon)
episode <- array(c(state,action,0),dim = c(1,4));
while (T) {
one_step <- CW_take_a_step(state,action)
next_state  <- one_step[[1]]
reward      <- reward + one_step[[2]]
if(identical(next_state,CW_end_pos)){
break
}
next_action  <- CW_get_action_epsilon_policy(Q,next_state,epsilon)
episode <- rbind(episode,c(next_state,next_action,reward))
state <- next_state
action <- next_action
}
return(episode)
}
CW_mc <- function(num_episodes = CW_num_episodes,
discount_factors = CW_discount,
epsilon=CW_epsilon,
Q = CW_reset_Q(),
using = "first"){
# traing the process and get the method
r_sum <- r_count <- array(0,dim = c(CW_map,4))
pb <- txtProgressBar(style=3)
Ts <- Gs <- numeric(CW_num_episodes)
start_time <- proc.time()[[3]] # record the time elapsed
for (i in 1:CW_num_episodes){
setTxtProgressBar(pb, i/CW_num_episodes)
episode <- CW_one_episode(Q,epsilon)
episode_len <- dim(episode)[1]
G <- 0
s_his <- array(0,dim = c(CW_map,4))
for (t in episode_len:1){
s_cur <- episode[t,1:2]
a_cur <- episode[t,3]
r_cur <- episode[t,4]
G <- discount_factors * G + r_cur
if ( (r_count[s_cur[1],s_cur[2],a_cur] == 0 & using == "first") | (using == "all")  ){
r_sum[s_cur[1],s_cur[2],a_cur]   <- r_sum[s_cur[1],s_cur[2],a_cur]   + G
r_count[s_cur[1],s_cur[2],a_cur] <- r_count[s_cur[1],s_cur[2],a_cur] + 1
Q[s_cur[1],s_cur[2],a_cur]       <- r_sum[s_cur[1],s_cur[2],a_cur]   / r_count[s_cur[1],s_cur[2],a_cur]
s_his[s_cur[1],s_cur[2],a_cur] <- 1
}
}
Gs[i] <- G
Ts[i] <- proc.time()[[3]] - start_time
}
close(pb)
return(list(Q,Gs,Ts))
}
CW_show_path <- function(Q,epsilon = 0){
# show path
path <- array(0,dim = CW_map)
state <- CW_start_pos
while (T) {
path[state[1],state[2]] <- path[state[1],state[2]] + 1
if (identical(state,CW_end_pos)){
break
}
action <- CW_get_action_epsilon_policy(Q,state,epsilon)
state  <- CW_take_a_step(state,action)[[1]]
if (sum(path) >= 1e5){
break
}
}
print(sum(path))
return(path)
}
CW_show_reward_and_pts <- function(Gs,Ts,remove0 = TRUE){
Tss <- Ts[-1] - Ts[-length(Ts)]
if (remove0 == TRUE){
Gs <- Gs[-1]
Ts <- Ts[-1]
Tss <- Tss[-1]
}
plot(1:length(Ts),Ts,type = "l",xlab = "episode")
plot(1:length(Tss),Tss,type = "l",xlab = "episode")
plot(1:length(Gs),Gs,type = "l",xlab = "episode")
}
load("../data/Q.rdata")
install.packages('../StatComp21047_1.0.tar.gz',repo=NULL)
